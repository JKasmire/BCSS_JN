{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![UKDS Logo](images/UKDS_Logos_Col_Grey_300dpi.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Being a Computational Social Scientist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Welcome to the <a href=\"https://ukdataservice.ac.uk/\" target=_blank>UK Data Service</a> training series on *New Forms of Data for Social Science Research*. This series guides you through some of the most common and valuable new sources of data available for social science research: data collected from websites, social media platorms, text data, conducting simulations (agent based modelling), to name a few. We provide webinars, interactive notebooks containing live programming code, reading lists and more.\n",
    "\n",
    "* To access training materials for the entire series: <a href=\"https://github.com/UKDataServiceOpen/new-forms-of-data\" target=_blank>[Training Materials]</a>\n",
    "\n",
    "* To keep up to date with upcoming and past training events: <a href=\"https://ukdataservice.ac.uk/news-and-events/events\" target=_blank>[Events]</a>\n",
    "\n",
    "* To get in contact with feedback, ideas or to seek assistance: <a href=\"https://ukdataservice.ac.uk/help.aspx\" target=_blank>[Help]</a>\n",
    "\n",
    "<a href=\"https://www.research.manchester.ac.uk/portal/julia.kasmire.html\" target=_blank>Dr Julia Kasmire</a> and <a href=\"https://www.research.manchester.ac.uk/portal/diarmuid.mcdonnell.html\" target=_blank>Dr Diarmuid McDonnell</a> <br />\n",
    "UK Data Service  <br />\n",
    "University of Manchester <br />\n",
    "May 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "# <h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Introduction\" data-toc-modified-id=\"Introduction-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Introduction</a></span></li><li><span><a href=\"#Quick-guide\" data-toc-modified-id=\"Quick-guide-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Quick guide</a></span><ul class=\"toc-item\"><li><span><a href=\"#Structure\" data-toc-modified-id=\"Structure-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Structure</a></span></li><li><span><a href=\"#Interaction\" data-toc-modified-id=\"Interaction-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Interaction</a></span></li><li><span><a href=\"#Table-of-Contents\" data-toc-modified-id=\"Table-of-Contents-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Table of Contents</a></span></li><li><span><a href=\"#Learn-more\" data-toc-modified-id=\"Learn-more-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>Learn more</a></span></li></ul></li><li><span><a href=\"#Why-be-a-Computational-Social-Scientist?\" data-toc-modified-id=\"Why-be-a-Computational-Social-Scientist?-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Why be a Computational Social Scientist?</a></span></li><li><span><a href=\"#How-do-I-be-a-Computational-Social-Scientist?\" data-toc-modified-id=\"How-do-I-be-a-Computational-Social-Scientist?-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>How do I be a Computational Social Scientist?</a></span></li><li><span><a href=\"#Big-Five-for-Computational-Social-Science\" data-toc-modified-id=\"Big-Five-for-Computational-Social-Science-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Big Five for Computational Social Science</a></span><ul class=\"toc-item\"><li><span><a href=\"#Thinking-computationally\" data-toc-modified-id=\"Thinking-computationally-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>Thinking computationally</a></span></li><li><span><a href=\"#Acquiring-data\" data-toc-modified-id=\"Acquiring-data-5.2\"><span class=\"toc-item-num\">5.2&nbsp;&nbsp;</span>Acquiring data</a></span></li><li><span><a href=\"#Writing-code\" data-toc-modified-id=\"Writing-code-5.3\"><span class=\"toc-item-num\">5.3&nbsp;&nbsp;</span>Writing code</a></span></li><li><span><a href=\"#Knowing-your-computational-environment\" data-toc-modified-id=\"Knowing-your-computational-environment-5.4\"><span class=\"toc-item-num\">5.4&nbsp;&nbsp;</span>Knowing your computational environment</a></span></li><li><span><a href=\"#Understanding-and-manipulating-unstructured/unfamiliar-data\" data-toc-modified-id=\"Understanding-and-manipulating-unstructured/unfamiliar-data-5.5\"><span class=\"toc-item-num\">5.5&nbsp;&nbsp;</span>Understanding and manipulating unstructured/unfamiliar data</a></span></li><li><span><a href=\"#Working-with-data\" data-toc-modified-id=\"Working-with-data-5.6\"><span class=\"toc-item-num\">5.6&nbsp;&nbsp;</span>Working with data</a></span></li><li><span><a href=\"#Documenting-and-enhancing-your-workflow\" data-toc-modified-id=\"Documenting-and-enhancing-your-workflow-5.7\"><span class=\"toc-item-num\">5.7&nbsp;&nbsp;</span>Documenting and enhancing your workflow</a></span></li><li><span><a href=\"#Visualising-data\" data-toc-modified-id=\"Visualising-data-5.8\"><span class=\"toc-item-num\">5.8&nbsp;&nbsp;</span>Visualising data</a></span></li></ul></li><li><span><a href=\"#Conclusion\" data-toc-modified-id=\"Conclusion-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Conclusion</a></span></li><li><span><a href=\"#Bibliography\" data-toc-modified-id=\"Bibliography-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Bibliography</a></span></li><li><span><a href=\"#Further-Reading-and-Resources\" data-toc-modified-id=\"Further-Reading-and-Resources-8\"><span class=\"toc-item-num\">8&nbsp;&nbsp;</span>Further Reading and Resources</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TO DO:\n",
    "* Change all links to `<a>` and `target=blank`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Computational Social Science: it can be a scary, alluring, mystifying term. You may even be thinking, what's the big deal? Surely almost all social science involves the use of computers: we code our interviews using software such as NVivo; build our statistical models in SPSS, Stata etc; and generally conduct our research and teaching activities within a computational environment (e.g., personal desktop/laptop, Dropbox or iCloud for file storage). However, computational social science (CSS) refers to activities and technologies that go beyond what we're typically familiar with as social scientists:\n",
    "* The use of datasets that are too large to store on your personal machine; \n",
    "* Writing programming scripts to access information held in online databases; \n",
    "* Employing analytical techniques, derived from computer science, that reveal structures and patterns in large or unfamiliar datasets (e.g. network analysis, text mining). \n",
    "\n",
    "More formally, CSS is an interdisciplinary branch of research, defined more by its methods and data than its substantive topics (Heiberger & Riebling, 2016). CSS is not limited to certain analytical approaches (e.g., Machine Learning) or data types (e.g., text data). So what makes CSS different from \"traditional\" social science? What are the techniques that are not well suited to familiar statistical software packages such as SAS, SPSS? And why would you want to be a computational social scientist?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table of Contents\n",
    "\n",
    "There is a table of contents provided at the top of the notebook, but you can also access this menu at any point by clicking the Table of Contents button on the top toolbar (an icon with four horizontal bars, if unsure hover your mouse over the buttons)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why be a Computational Social Scientist?\n",
    "\n",
    "### Start with Human Thinking about human problems\n",
    "\n",
    "Human thinking co-evolved with human problems. Specifically, human thinking co-evolved with the kind of human problems were persistent, frequent or important enough throughout their evolutionary history to drive adaptation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### REALLY basic human problems include really basic animal problems like 'staying alive':\n",
    "\n",
    " - Responding to stimulus, including dangers that are both fast (like tigers) and slow (like the approach of winter) as well as useful things (like resources). \n",
    " - Learning in order to turn the unknown into the known so it can be responeded to appropriately (as dangerous, useful, etc.).\n",
    " - Recognising patterns so as to respond more quickly to known patterns as stimulus or to pique curiosity and drive learning around new patterns. \n",
    "\n",
    "#### Human problems also include less basic problems like 'other people':\n",
    "\n",
    " - Understanding the intentions, or likely intentions, of the people around us. \n",
    " - Predicting likely next actions or responses. \n",
    " - The role of intentions, actions and responses within wider patterns like collaboration, competition or some combination of them both.\n",
    "\n",
    "Solving these problems involve a kind of thinking that doesn’t exactly look like “thinking”. \n",
    " - People often respond to perceived dangers even before they were consciously aware of the danger. \n",
    " - People don't have to put a whole lot of mental effort into learning things like \"Avoid the snarling animal\" or \"Don't eat the bitter tasting fruit\". \n",
    " - People don’t really sit down and deliberately set out to compare the footsteps heard on the stairs against the known footsteps of the housemate or not. \n",
    " - People can recognise other people, read their faces, judge a situation and react all before they can consciously think about it.\n",
    " \n",
    " Most of these examples of common human thinking are nearly always invisible. These are not examples of **irrational** thinking so much as **sub-rational** thinking that operates at intstinctual levels, much faster than those that underpin rational thinking."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The typical problems humans have (in an evolutionary sense) drives the kind of thinking we use, its limits, its work-arounds, etc. \n",
    "\n",
    "- Working memory capacity according to Kimberg, 1997 :\n",
    "    - Limited focus - We can only hold between 1 and 7 things in mind at once. \n",
    "    - Complexity matters - We can hold fewer complex things in mind. \n",
    "    - Different capacity for structured vs. unstructured - complex but structured things are easier than complex and unstructured things.\n",
    "    - Chunking (and others) as a work-around strategy - We have ways of creating structure to help us work with more/more complex things. \n",
    "- Bounded rationality according to Simon, 1997:\n",
    "    - Satisficing - People tend to go with 'good enough' solutions for many things, especially when time or complexity is an issue. \n",
    "    - Heuristics  - We use a lot of 'rules of thumb' to short cut decision-making, speeding up how we arrive at 'good enough' solutions.\n",
    "- Communication assumptions according to Pinker, 2003 :\n",
    "    - Speaker and listener interpret the same way - We all assume others will understand something the way *we would have* understood it if we were the listener.\n",
    "    - Objects and actions as distinct - We assume new terms to be either objects or actions, but not both.\n",
    "    - Mid-level categories, but with knowledge of hierarchies - We assume a generic term like 'cat' to mean a household pet, rather than all felines in taxonomic terms or 'this particular cat, right now'. \n",
    "    - Transitive properties - We apply logical operations, so \"The book that is on the desk\" might actually mean \"the book on top of the paperwork that is on the desk\". \n",
    "- 2 types of thinking according to Kahneman, 2011:\n",
    "    - Fast, error-prone, intuition-based - this is the sub-rational stuff.\n",
    "    - Slow, (more) accurate, rationality-based - still not perfectly rational, but often with conscious effort involved"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next, consider Computer Thinking...\n",
    "\n",
    "Computers do not have computer problems, at least not in the sense that humans have human problems. Without intervention, a computer does not try to stay alive, to communicate, to learn about its surroundings... Basically, computers just do computer thinging about human problems. \n",
    "\n",
    "And humans have tried to give computers ALL KINDS of human problems. Not all of that has worked equally well, because computers do not have the kind of co-evolutionary drive linked to human problems that humans have had. Nevertheless, they are very good at dealing with some problems, especially those that humans are **not good at**. For example, problems that:\n",
    "\n",
    " - Vast problems that exceed human working memory capacity, either through the number of elements involved, the complexity of elements, or both.\n",
    " - Hyper rational problems that require the best answer, not the best answer that can be found quickly.\n",
    " - Non-interpretive problems that do not have any embedded reciprocal, creative or assumed communication.\n",
    "\n",
    "It is important to remember that computers thinking has *different* limitations when compared to human thinking. There are still limits, shortcuts and workarounds to drive efficiency, but these are in other areas and make computer thinking better or more efficient at some tasks than others. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Those differences inlude: \n",
    "|          Humans             |          Computers            |\n",
    "|-----------------------------|-------------------------------|\n",
    "|       Abstract concepts     |       Concrete definitions    |\n",
    "|         Inference           |   Defined terms/rules only    |\n",
    "| Shared/background knowledge | Nothing carried outside scope |\n",
    "|      Fuzzy categories       |        Strict categories      |\n",
    "|      Context-dependence     |           Absolutes           |\n",
    "|-----------------------------|-------------------------------|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why it matters\n",
    "\n",
    "#### Some problems need both human thinking and computer thinking to solve...\n",
    "\n",
    "Human thinking is typically needed to identify the problem, possible solutions, relevant info, etc. This is especially true of problems that deal with humans and human behaviour. For example, trying to predict how people will react to an innovation, a policy change, a new trend, etc. requires understanding and predicting how people will interpret new information, how they will apply that information to their diverse personal goals and fears, how they will choose to react (hopefully) in line with existing laws and societal norms, etc. At the same time, computer thinking if the dealing with that problem involves working accurately and reproducibly with large volumes of (complex) data. \n",
    "\n",
    "For example, imagine a new law is proposed that makes smart meters obligatory for all new houses. Social science researchers could think about how people might react using only human thinking to create some abstract scenarios and identify potential problems. But if those social scientists want to know how people *actually* react, then they will need to collect quite a lot of potentially very complex data, ideally from different sources (interviews, smart meter data, social media discussions, freedom of information requests, etc.). Computer thinking is required to integrate that vast and complex data in useful ways. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "#### The problems that need both human thinking and computer thinking are new research opportunities\n",
    "\n",
    "The first principles argument for engaging in CSS is as follows: working with new forms of digital data and analytical methods opens up a whole new galaxy of potential research opportunities. That's a rather grand statement but it's true: vast swathes of our social interactions and personal behaviours are conducted online and/or captured digitally. Our use of social media platforms such as Facebook, Twitter and Instagram generates astounding amounts of data, much of which is available from these platforms if you have the right programming skills. Snapshots of our daily lives are routinely captured and aggreagted into large, rich administrative datasets (e.g., our health and social care records, educational achievements). The value of CSS goes beyond these obvious examples: websites can be scraped and marshalled into statistically-usable datasets, documents aggregated into large corpora of text information that can be mined for interesting patterns (e.g., through sentiment analysis). In summary, many new forms of data are only available through computational means (Kitchin, 2014).\n",
    "\n",
    "Halford and Savage (2017) outline further advantages to engaging in CSS, especially from a data perspective:\n",
    "* Utilise techniques for handling and analysing large-scale, unstructured data. \n",
    "* Capture data that is generated in real time and over time.\n",
    "* Access information on new/previously unmeasured activities.\n",
    "* Access information on familiar/currently measured activities at an unprecedented scale, dynamism or complexity.\n",
    "* It's happening whether we (social scientists) like it or not (see also Heiberger & Riebling, 2016); empirical social science in general is having its moment in the sun, in much the same way the social theorists did in the recent past.\n",
    "\n",
    "\n",
    "Last but certainly not least, there's more to CSS than boosting your research standing or productivity. I rather like Sociologist Dr James Allen-Robertson's thoughts on this:\n",
    "\n",
    "> In response to the question of what computational social science has helped me achieve, it may seem obvious to mention the concrete projects, the outputs, the measurable outcomes. However, for me computational social science has achieved something more substantial and enduring — a new way of working, a new way of thinking, and a new kind of enthusiasm for research.<sup>[1]</sup>\n",
    "\n",
    "[1]: https://campus.sagepub.com/blog/james-allen-robertson-css-blog\n",
    "\n",
    "There are limitations with CSS of course, particularly around ethical consent needed to access and use these new forms of data, computational resources and capacity (e.g., hard drive space, memory), and data quality issues (see Halford and Savage, 2017). But one aspect which should not curtail your aims and activities in this space is your ability *to write code* and *manipulate data*. That's not to say that either skill is easy to obtain, on the contrary they require a mode of thinking and intellectual dexterity that you may not have practiced before. However, the crucial thing to remember is this: a little ability goes a long way. You do not need to attain the rank of software engineer to successfully scrape a website, nor invest in your own high-performance computing environment or server to manipulate data accessed through Spotify or Twitter. Brooker (2020) calls this approach the \"grilled cheese\" methodology for programming: your activities just need to be effective i.e., produce the results you need or expect. Elegance, concision and optimisation (e.g., shaving milliseconds off the running time of your code) can come later - or not at all - as a computational social scientist.\n",
    "\n",
    "The good news is the field is sufficiently mature that the code and tools necessary to be a computational social scientist are readily accessible and masterable in a short period of time (think weeks instead of months/years). The aim - in the short-term at least - is not to learn everything about a particular technique, but enough to achieve your research aim e.g., write an executable programming script for collecting data from Wikipedia; Dr James Allen-Robertson again:<sup>[1]</sup>\n",
    "\n",
    "> What mattered here wasn’t necessarily the nuts and bolts of the techniques I was learning, but the development of a 'methodological imagination' and an understanding of the application of these techniques.\n",
    "\n",
    "This may seem unambitious, to grasp the basic concepts and be able to implement foundational techniques, but even this is enough to be able to understand the implications of new forms of data/techniques for your work. Which brings us to our final key point: social science research is increasingly interdisciplinary and knowledge of computational social science techniques puts you in an advantageous position for attracting research funding, securing permanent academic positions etc (Brooker, 2020). My message is clear: embrace this new world with enthusiasm and a critical and reflexive mindset.\n",
    "\n",
    "<!--Material added by JK, needs to be worked in -->\n",
    "<!-- * We live in a world of data (what does that even mean?!?). In fact, we pretty much always have been, although in the pre-digital ages most of that data is probably not what we would consider to be “data” in the way that we understand it now. But it was data nonetheless! As data accumulated, it began to be a problem. How does someone remember it all? How can someone make sure that the right person has new data? How can someone get to the right bit of data at the right time? How best to ensure data is accurate? Fortunately, people developed some pretty good methods for dealing with the problems. These included systems for learning, transferring, testing and accessing data. For example; writing systems allowed data to be transmitted without relying on a specific living messenger being privy to the message, the scientific method allowed insights and discoveries to be replicated ensuring data accuracy, and the dewey decimal system allowed library goers to quickly zoom in on areas that are most likely to have relevant data.  The world of data that surrounds us now includes digital data... Obviously “data-ish” data. And, sensibly, we have developed some methods of dealing with digital data, some based on the data methods developed for non-digital data. Storage drives full of folders with sensible names, for example, are like digital versions of libraries with organised shelves. I am sure you can all imagine more examples.  But, problematically, our modern data world now includes some (very) fast data. Not all of the long-established data methods are well-suited to the fast-moving digital data. For example, the idea that data should be carefully divided into documents, labelled, and stored does not work especially well for data that is continuous, spread over many sources, subject to change, or that is most useful when rapidly accessed.   \n",
    "\n",
    "* Social sciences have traditionally used certain kinds of (slow) data \n",
    "* Social sciences may need to embrace computational thinking in order to use the (very) fast data  -->\n",
    "\n",
    "<!-- What is data and how is it different than information? \n",
    "There is a subtle difference between data and information. Data are the facts or details from which information is derived. Individual pieces of data are rarely useful alone. For data to become information, data needs to be put into context. \n",
    "Data exists, as it were, out there in the world. Information is created, for a purpose, by interpreting data within a given context.  \n",
    "What kind of data are humans good at using? And computers? \n",
    "Humans tend to be good at finding patterns in messy, sparse or irregular data. This is to say, humans are good at deriving information out of minimal data. In theory, this is because we have an evolutionary drive to jump to conclusions as quickly as possible – it is better to flee from the tiger that you think you can hear creeping up behind you than to carry on gathering data about what might be causing the sound of approaching footsteps in the jungle. However, evolution-driven instincts are most applicable to evolutionary problems, so humans tend to be better deriving information efficiently from situations that involve immediate danger, other people, food, and other basic life situations. A good example is how almost all people acquire language in early childhood from the erratic and error-prone output of people around them under often difficult or unusual conditions. This is because language is a clear advantage for a species that reliably exists in a social and communicative context, both in the context of turning the jumble of noise that comes out of people’s mouths into coherent messages and in the context of language acquisition, in which a jumble of noise is turned into a syntax, vocabulary, etc.  \n",
    "Likewise, people are very good at detecting faces, even doing so in tortilla scorch marks or clouds of smoke, even though the detected faces are detected against strange backgrounds, in all lighting conditions, at unpredictable angles and contrary to all expectations. This is because detecting human faces, in a wide range of potentially surprising conditions, is also a clear advantage to a social species like humans. Consequently, humans are very good at picking up on some very subtle and complex patterns in very challenging conditions.  \n",
    "In contrast, humans are not good at reliably and accurately churning through boring and predictable data. Humans get bored, attention wanders, errors are made. In situations were errors have catastrophic consequences, then you really don’t want to rely on a human to be paying attention to a boring stream of data. Computers though, are very good at reliably working with boring data. You want a measurement added to a list once per hour? You want a computer for that!  \n",
    " \n",
    "What problems arise when the differences between human and computer approaches to data are not acknowledged or dealt with? \n",
    "Errors in contexts where errors matter is the biggest problem of asking humans to do computer-things. On the other side, meaningless or counter-productive choices are the result of trusting data when information is actually more valuable.   -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## How do I be a Computational Social Scientist?\n",
    "\n",
    "Though there are myriad aspects to the role, being a computational social scientist typically involves one or more of the following practices:\n",
    "* Writing programming scripts to collect and manipulate data.\n",
    "* Employing analytical techniques - many derived from computer/information sciences - to reveal patterns in data.\n",
    "* Using technological tools and e-Research best practice to structure and document your research workflow.\n",
    "\n",
    "The good news is, as a trained social scientist, you do not need to learn al of these aspects from scratch and can instead apply the knowledge, skills and strengths that you have already! For example, social scientists possess knowledge - theoretical and empirical - of social systems and phenomena and already have advanced data skills, especially around:\n",
    " - categorising and coding responses (qualitative and/or quantitative), \n",
    " - evaluating data quality (e.g., why is this survey response missing?), and \n",
    " - making inferences from data (e.g., how representative is this pattern of a larger population?). \n",
    " \n",
    "Thus, main gaps in your skillset concern one or more of the following:\n",
    " - awareness of computational structure and processes, \n",
    " - experience with or knowledge of computational and/or data resources, \n",
    " - programming skills and knowledge of programming languages, and \n",
    " - experience with or knowledge of how to document work to improve reproducibility, and \n",
    " - communicating about computational social science. \n",
    " \n",
    "We'll explore many examples of each throughout this [book/training series], but for now we're going to focus on the skills and behaviours that underpin the above activities. Let's call these our *Big Five for CSS*:\n",
    "1. Knowing your computational environment\n",
    "2. Acquiring, understanding and manipulate data\n",
    "3. Writing code\n",
    "4. Documentation and reproducibility\n",
    "5. Communicating effectively"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- ## Big Five for Computational Social Science\n",
    "\n",
    "General structure of each section:\n",
    "1. Theory/abstract\n",
    "2. Practical instantiation\n",
    "3. Reproducibility -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- ### Thinking computationally\n",
    "\n",
    "[Barba et al. (2019)](https://jupyter4edu.github.io/jupyter-edu-book/)\n",
    "\n",
    "* Decomposition: Breaking down data, processes, or problems into smaller, manageable parts\n",
    "* Pattern Recognition: Observing patterns, trends, and regularities in data\n",
    "* Abstraction: Identifying the general principles that generate these patterns\n",
    "* Algorithm Design: Developing the step by step instructions for solving this and similar problems\n",
    "\n",
    " -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Knowing your computational environment\n",
    "\n",
    "All computational social science activities are dependent on knowing how to setup, manage and share a computational environment. This can be as simple as understanding how and where files are located on your machine, to defining and documenting which software packages, versions and configurations are necessary to execute your data analysis. Whether you are thinking about scraping a web page or implementing an advanced machine learning algorithm, it all begins with establishing your computational environment. First, let's understand how files are stored and accessed on your machine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### File system and working directory\n",
    "\n",
    "It is critical that you think *logicially* and in an *organised* way about how you manage and store files for your project. This goes beyond just keeping your filesd and folders tidy using a graphic user interface, and requires that you know how to move around in and interpret command line interfaces. Although this may look a bit unfamiliar or even scary, the black window with stark contrast text and a blinky cursor will become your friend!\n",
    "\n",
    "First thing to know is that files and folders stored on your machine's hard drive can and be accessed in two ways:\n",
    "Absolute path \n",
    "Relative path\n",
    "\n",
    "Both the absolute and relative path are like directions to the location of a file or folder, but they differ in that relative path assumes that whoever is giving directions is in the same place as whoever is getting the directions while absolute path does not. \n",
    "\n",
    "For example, if someone were to ask me \"Where is your office?\" I would answer differently in different contexts. If I was talking on the phone to someone who wanted to send a book to my office, I would respond with an absolute path type answer and give the full postal address of my office. But if someone where standing in the lobby of my building and asked me where to drop something off after lunch, I would give a relative path answer and say which floor and which hallway to take out of the stairwell, plus my office number. \n",
    "\n",
    "It is not always easy to know whether you (the one giving the directions) are in the same file system location as the computer (the one giving directions), so you need to know how to ask for the current working directory (i.e., where *this* notebook, that you are working in right now is located).\n",
    "\n",
    "One way to do that is to ask by double clicking in the code cell below, just after the end of %cd%. Then either \n",
    "- hit the \"Run\" button at the top of the page or \n",
    "- use the keyboard shortcut Shift + Enter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mzyssjkc\\GitWork\\BCSS_JN\n"
     ]
    }
   ],
   "source": [
    "!echo %cd%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What this is doing is asking the computer to repeat out loud (or 'echo') its current working directory (or 'cd'). This happens to be structured very much like an English language command, with the verb at the front and the object at the end, not unlike a \"Pass the salt\" or \"Close the door\". \n",
    "\n",
    "When you run a command like this in a code cell, the computer will execute the code and echo back to you its current directory. \n",
    "\n",
    "Another way to do that is to import a library called os (which stands for operating system) and ask the computer to use an os command called getcwd (short for get current working directory). Like the echo command above, this tells the computer to report where in the file structure it is currely at. Try double clicking in the code cell below and hitting \"Run\" or Shift + Enter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\mzyssjkc\\\\GitWork\\\\BCSS_JN'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unlike the echo command, this one is not structured so much like an English language command. Instead, it translates (more or less) to \"Using os, run the getcwd command (here)\". \n",
    "\n",
    "Although it is less English-like, os is very useful. For example, it you can use it to get a list the contents of a directory. Put another way, that means \"Tell me everything that is in this folder\". Go ahead and double click/Run in the next cell. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.git',\n",
       " '.ipynb_checkpoints',\n",
       " 'bcss-code-2020-05-06.ipynb',\n",
       " 'convert-data-structures-2010-03-16.ipynb',\n",
       " 'data',\n",
       " 'images',\n",
       " 'outlines',\n",
       " 'Quick_Guide_to_Jupyter_Notebooks.ipynb',\n",
       " 'README.md',\n",
       " '_config.yml']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir() # return contents of current working directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Roughly translated, this command says \"Using os, run list the contents of the directory (here)\"\n",
    "\n",
    "But you can also use it to list the contents of directories that are in *other* places without you having to move to that place and use os.listdir().  \n",
    "\n",
    "Double click/Run in the next code cell to see how that works. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['oxfam-csv-2020-03-16.csv',\n",
       " 'oxfam-csv-2020-03-16.json',\n",
       " 'oxfam-csv-2020-03-16.xml']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(\"./data/\") # return contents of the \"data\" directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Environments\n",
    "\n",
    "Your computational environment consists of hardware (e.g., the physical machine and its Central Processing Unit) and software (e.g., operating system, programming langauges and their versions, files). For instance, here is a snapshot of my computational environment as of 2020-03-30; first, the operating system:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "OS Name:                   Microsoft Windows 10 Enterprise\n",
    "OS Version:                10.0.17763 N/A Build 17763\n",
    "OS Manufacturer:           Microsoft Corporation\n",
    "Original Install Date:     28/02/2020, 16:42:11\n",
    "System Boot Time:          28/02/2020, 16:54:15\n",
    "System Manufacturer:       LENOVO\n",
    "System Model:              20NYS2B800\n",
    "System Type:               x64-based PC\n",
    "Processor(s):              1 Processor(s) Installed.\n",
    "                           Intel64 Family 6 Model 142 Stepping 12 G\n",
    "Total Physical Memory:     16,132 MB\n",
    "Available Physical Memory: 8,349 MB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And my version of Python, plus some of the additional packages installed:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Python 3.7.3\n",
    "\n",
    "qgrid==1.3.0\n",
    "QtAwesome==0.6.1\n",
    "qtconsole==4.7.1\n",
    "QtPy==1.9.0\n",
    "requests==2.23.0\n",
    "retrying==1.3.3\n",
    "rise==5.6.1\n",
    "rope==0.16.0\n",
    "ruamel-yaml==0.15.87\n",
    "scikit-image==0.16.2\n",
    "scikit-learn==0.22.1\n",
    "scipy==1.4.1\n",
    "seaborn==0.10.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computational environments tend to be unique: for example, you may have different software applications installed on your machine compared to your classmate; or some machines in your computer lab run Windows 10, others Windows 7. This customisability presents considerable challenges for conducting, sharing and reproducing scientific work. In the words of the Turing Institute:<sup>[5]</sup>\n",
    "> The analysis should be *mobile*. Mobility of compute is defined as the ability to define, create, and maintain a workflow locally while remaining confident that the workflow can be executed elsewhere.\n",
    "\n",
    "Trying and failing to reproduce a piece of work after switching to a new machine is, frankly, soul destroying. Thankfully, there are numerous, simple technological solutions for capturing and sharing your computational environment.\n",
    "\n",
    "##### Capturing a computational environment\n",
    "\n",
    "An environment is analogous, in that it acts as a means of _partitioning_ your machine into separate units, each one customised for a certain project. For example, on one of my machines I have two environments: one for collecting charity data for Australia; and another for interacting with the [Companies House API](https://developer.companieshouse.gov.uk/api/docs/). Each environment has Python installed but customised with different Python packages - for example, I do not perform any web-scraping for the Companies House project, therefore I did not install `requests` or `BeautifulSoup` on this environment. The benefit of this approach becomes apparent when you need to use a wide variety of functions/commands in your work and certain packages rely on a specific version of other packages. If you use one environment for multiple pieces of work, your scripts may break as you upgrade packages to newer versions. Running separate environments for different projects allows you to manage these package dependencies carefully and correctly.\n",
    "\n",
    "Interacting with and undertanding your computer at a more fundamental level is also excellent training for running your own server for research (or other) purposes. What is a server? Think of it as a more powerful form of personal computer, running in the cloud, and your primary means of communicating with it is through the Command Line Interface (CLI). It is always on (barring any planned or unplanned downtime) and thus is particularly useful for running automated, scheduled tasks e.g. conducting a weekly scrape of a particular web page.\n",
    "\n",
    "[5]: https://the-turing-way.netlify.com/reproducible_environments/reproducible_environments.html\n",
    "\n",
    "<!-- Material added by JK to be worked in -->\n",
    "<!-- Learning to code (it is not as scary as you think) \n",
    "Why coding is useful \n",
    "What coding languages should you bother with learning \n",
    "But how do you actually “do” the coding \n",
    "More on this  -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Acquiring, understanding and manipulating unstructured/unfamiliar data\n",
    "\n",
    "#### Acquiring data\n",
    "There are LOADS of ways to get data, some that are more 'computational' than others. You are all surely familiar with surveys and interviews, as well as Official data sources and data requests. You may also be familiar with (at least the concepts of):\n",
    " - scraped data that comes from web-pages or APIs\n",
    " - “found” data that is captured through alongside orinigally intended data targets\n",
    " - meta-data, which is data about data\n",
    " - repurposed data, or data collected for some other purspose that is used in new and creative ways or \n",
    " - other... cause this list is definitely not exhaustive. \n",
    " \n",
    " To some extent, using these data sources requires that you keep your ear to the ground so that you know when relevant new sources come available. But once you know *about* them, you still need to know *how* to access and use them. That (hopefully) is where we come in!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data literacy - the ability to manipulate a wide variety of different types of data - is front-and-centre in computational social science. Why do you need computional skills for handling data? Picture the following scenarios:\n",
    "* You've found a website that publishes statistics about a phenomenon of interest, however these are updated daily and you do not have the time to extract the figures, copy them to a new row in a file etc.\n",
    "* You would like to analyse \n",
    "\n",
    "Being data literate involves understanding two key properties of datasets:\n",
    "1. How the contents of the dataset are stored (e.g., as numbers and/or text).\n",
    "2. How the contents of the dataset are structured (e.g., as rows of observations, or networks of relations).\n",
    "\n",
    "#### Data types\n",
    "\n",
    "Data types provide a means of classifying the contents (values) of your dataset. For example, in [Understanding Society](https://www.understandingsociety.ac.uk/) there are questions where the answers are recorded as numbers e.g., [`prfitb`](https://www.understandingsociety.ac.uk/documentation/mainstage/dataset-documentation/variable/prfitb) which captures total personal income; [One more example of qualitative variable]\n",
    "\n",
    "Data types are important as they determine which values can be assigned to them, and what operations can be performed using them e.g., can you calculate the mean value of a piece of text (Tagliaferri, n.d.)?<sup>[4]</sup> Let's cover some of the main data types in Python.\n",
    "\n",
    "[4]: https://assets.digitalocean.com/books/python/how-to-code-in-python.pdf\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <!-- Material added by JK to be worked in -->  \n",
    " <!-- Structured vs. unstructured (or more accurately, semi-structured) data \n",
    "# Fully structured data vs. completely unstructured data \n",
    "# Real-world data  \n",
    "# Practical matters, or Rows and columns vs. free text \n",
    "\n",
    "\n",
    "# <!-- Think hard about data \n",
    "# Do you start by thinking about ideal data and then try to acquire the best possible match? \n",
    "# Or do you start with what is available and try to find the most useful thing to say about it? \n",
    "# Bit of both? What are the limitations? \n",
    "#  Searching structured data \n",
    "# Regular expressions \n",
    "# Databases \n",
    "# Hierarchies (semantic web, ontologies, etc.) \n",
    "# Other? \n",
    "# Searching un/semi-structured data \n",
    "# Regular expressions again \n",
    "# Free text fields \n",
    "# Text-mining \n",
    "# Machine learning \n",
    "# Deep learning \n",
    "# Edge-detection \n",
    "# AI \n",
    "# Other?  -->\n",
    "\n",
    " <!-- ### Working with data\n",
    "#  -->\n",
    " <!-- Ideal or tidy data \n",
    "# Cutting and subsetting \n",
    "# Joining and merging \n",
    "# Recoding values \n",
    "# Coding data \n",
    "# Other? \n",
    "# Combining and cleaning data \n",
    "# Combining data with and without a common field \n",
    "# Cleaning messy, incomplete, or inconsistent data \n",
    "# Embrace the mess – using missing/incomplete/inconsistent data as a source of information  -->\n",
    " <!-- More material added by JK. Will this be another of the \"Big Five\"? Or maybe work into an existing section. But data prep is so important that it seems like it could be a section on its own.  -->\n",
    "\n",
    "\n",
    " <!-- Another item in the \"Big Five\"? or Just part of thinking computationally? Something to get people out of their normal mindsets of \"How do I answer this research question...?\" -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Numbers\n",
    "\n",
    "These can be integers or floats (decimals)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Integers\n",
    "\n",
    "myint = 5\n",
    "yourint = 10\n",
    "print(\"Summing integers: \", myint + yourint)\n",
    "\n",
    "# Floats\n",
    "\n",
    "myflo = 5.5\n",
    "yourflo = 10.7\n",
    "print(\"Summing floats: \", myflo + yourflo)\n",
    "\n",
    "# Combining integers and floats\n",
    "\n",
    "newnum = myint + myflo\n",
    "print(\"Data type when we sum an integer and a float: \", type(newnum))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Strings\n",
    "\n",
    "This data type stores text information. Strings are immutable in Python i.e., you cannot permanently change its value after creating it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strings\n",
    "\n",
    "mystring = \"This is my first string.\"\n",
    "print(mystring)\n",
    "\n",
    "yourstring = mystring.replace(\"my\", \"your\") # replace the word \"my\" with \"your\"\n",
    "print(yourstring)\n",
    "\n",
    "splitstring = yourstring.split(\"your\") # split into separate strings\n",
    "print(splitstring)\n",
    "\n",
    "# Add more material from other notebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Manipulating strings will be a common and crucial task during your computational social science work. We'll cover intermediate and advanced string manipulation throughout these training materials but for now we highly suggest you consult the resources listed below.\n",
    "\n",
    "*Further Resources*:\n",
    "* [Principles and Techniques of Data Science](https://www.textbook.ds100.org) - Chapter 8.\n",
    "* [Python 101](https://python101.pythonlibrary.org) - Chapter 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Boolean\n",
    "\n",
    "This data type captures true or false values (think of dummy/indicator variables that you may have used in Stata, SPSS etc). Boolean data allow us to evaluate expressions or calculations (e.g., is one variable equal to another? Is this word found in a paragraph?)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boolean\n",
    "\n",
    "result = (10+5) == (14+1) # check if two sums are equal\n",
    "print(result) # print the value of the \"result\" object\n",
    "print(type(result)) # print the data type of the \"result\" object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Booleans are also very useful for controlling the flow of your code: in the below example, we assign somebody a grade and then evaluate whether the grade is above a threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grade = 71\n",
    "\n",
    "if grade >= 40:\n",
    "    print(\"Congratulations, you have passed!\")\n",
    "else:\n",
    "    print(\"uh oh, exam resits for you.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(grade >= 40) # evaluate this expression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Further Resources*:\n",
    "* [How To Code in Python](https://assets.digitalocean.com/books/python/how-to-code-in-python.pdf) - Chapter 21."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Lists_\n",
    "\n",
    "The list data type stores an ordered, mutable (i.e., you can change its values) sequence of elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a list\n",
    "\n",
    "numbers = [1,2,3,4,5]\n",
    "print(numbers)\n",
    "\n",
    "strings = [\"Hello\", \"world\"]\n",
    "print(strings)\n",
    "\n",
    "mixed = [1,2,3,4,5,\"Hello\", \"World\"]\n",
    "print(mixed)\n",
    "\n",
    "mixed = [numbers, strings]\n",
    "print(mixed) # this is a list of lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List length\n",
    "\n",
    "length = len(numbers)\n",
    "print(\"The numbers list has {} items\".format(length)) \n",
    "# the curly braces act as a placeholder for what we reference in .format()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accessing items (elements) within a list\n",
    "\n",
    "print(\"{} is the second item in the list\".format(numbers[1]))\n",
    "# note that the position of items in a list (known as its 'index position')\n",
    "# begins at zero i.e., [0] represents the first item in a list\n",
    "\n",
    "# We can also loop through the items in a list:\n",
    "\n",
    "print(\"\\r\") # add a new line to the output to aid readability\n",
    "for item in numbers:\n",
    "    print(item)\n",
    "# note that the word 'item' in the for loop is not special and\n",
    "# can instead be defined by the user - see below   \n",
    "\n",
    "print(\"\\r\")\n",
    "for chicken in numbers:\n",
    "    print(chicken)\n",
    "# of course, such a silly name does nothing to aid interpretability of the code    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding or removing items in a list\n",
    "\n",
    "numbers.append(6) # add the number six to the end of the list\n",
    "print(numbers)\n",
    "\n",
    "numbers.remove(3) # remove the number three from the list\n",
    "print(numbers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Dictionaries_\n",
    "\n",
    "The dictionary data type maps keys (i.e., variables) to values; thus, data in a dictionary are stored in key-value pairs (known as items). Dictionaries are useful for storing data that are related e.g., variables and their values for an observation in a dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a dictionary\n",
    "\n",
    "dict = {\"name\": \"Diarmuid\", \"age\": 32, \"occupation\": \"Researcher\"}\n",
    "print(dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accessing items in a dictionary\n",
    "\n",
    "print(dict[\"name\"]) # print the value of the \"name\" key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dict.keys()) # print the dictionary keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dict.items()) # print the key-value pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining with lists\n",
    "\n",
    "obs = [] # create a blank list\n",
    "\n",
    "ind_1 = dict # create dictionaries for three individuals\n",
    "ind_2 = {\"name\": \"Jeremy\", \"age\": 50, \"occupation\": \"Nurse\"}\n",
    "ind_3 = {\"name\": \"Sandra\", \"age\": 41, \"occupation\": \"Chef\"}\n",
    "\n",
    "for ind in ind_1, ind_2, ind_3: # for each dictionary, add to the blank list\n",
    "    obs.append(ind)\n",
    "\n",
    "print(obs)# print the list\n",
    "print(\"\\r\")\n",
    "print(type(obs)) # now we have a list of dictionaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Social science applications_\n",
    "\n",
    "You may be wondering how the above examples have social science applications. To answer, here is an example from my research. Let's say I want to scrape First, I want to define a list of charity numbers that I "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data structures\n",
    "\n",
    "Indulge me: close your eyes and visualise a dataset. What do you picture? Heiberger and Riebling (2016, p. 4) are confident they can predict what you visualise:\n",
    "\n",
    "> Ask any social scientist to visualize data; chances are they will picture a rectangular table consisting of observations along the rows and variables as columns.\n",
    "\n",
    "This dataset (also known as a variable-by-case matrix or data frame) is a type of data structure: it stores values (e.g., text or numbers) in variables (e.g., strings or integers) in rows for _n_ number of observations. [Comment on why this is not always the best structure e.g. network data] As you engage in computational social science, you will encounter many more types of data structure, some of which may be unfamiliar; for now let's focus on some of the more common ones. We'll use some sample data - organisational and financial information for the charity [Oxfam](https://beta.charitycommission.gov.uk/charity-details/?regId=202918&subId=0) - to demonstrate and compare the properties of each data structure.\n",
    "\n",
    "##### Data frame\n",
    "\n",
    "A data frame is a rectangular data structure and is often stored in a Comma-Separated Value (CSV) file format. A CSV stores observations in rows, and separates (or \"delimits\") each value in an observation using a comma (','). Let's examine a CSV dataset in Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv # module for handling CSV files\n",
    "\n",
    "with open(\"./data/oxfam-csv-2020-03-16.csv\", \"r\") as f: # open file in 'read mode' and store in a Python CSV object called 'reader'\n",
    "    reader = csv.reader(f) # read data in file\n",
    "    for row in reader: # for every row in the data, print the contents of the row\n",
    "        print(row) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Though not as readable as we would like (compared to opening the file in Excel, Stata etc), we can clearly identify the structure of this file:\n",
    "* the first row contains the variables;\n",
    "* the following rows contain values for those variables, separated by commas; and\n",
    "* each row is clearly defined as beginning on a new line\n",
    "\n",
    "There is another way of opening CSV files and handling their contents: using the `pandas` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # module for handling data frames\n",
    "\n",
    "df = pd.read_csv(\"./data/oxfam-csv-2020-03-16.csv\") # open the file and store its contents in the \"df\" object\n",
    "df # view the data frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Being able to work with CSV files is a fairly simple but crucial skill as a computational social scientist: many open-source datasets are shared in this format, and transforming more complicated data structures to CSV files can aid your data analysis workflow (e.g. importing the subsequent CSV file into Stata or R).\n",
    "\n",
    "Now let's look at the same information but stored in a different data structure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Dictionaries\n",
    "\n",
    "A dictionary is a hierarchical data structure based on key-value pairs. Dictionaries are often stored as Javascript Object Notation (JSON) files. Let's examine a JSON dataset in Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json # import Python module for handling JSON files\n",
    "\n",
    "with open('./data/oxfam-csv-2020-03-16.json', 'r') as f: # open file in 'read mode' and store in a Python JSON object called 'data'\n",
    "    data = json.load(f)\n",
    "          \n",
    "data # view the contents of the JSON file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once again, readability is not great (see appendix A for other ways of viewing the contents of a JSON file) but we can pick out the core properties of the data structure:\n",
    "* A dictionary begins with '{' and ends with '}';\n",
    "* It can contain nested dictionaries - for example, the value of the first key ('name') is itself a dictionary containing ten key-value pairs (e.g. '0': '01/05/2008 00:00'); and\n",
    "* key-value pairs are separated by a comma (',').\n",
    "\n",
    "Let's dig into some of these properties in more detail:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.keys() # view the keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.values() # view the values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.items() # view the key-value pairs (items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['fye']['9'] \n",
    "# view the value of the '9' subkey under the 'fye' key i.e. the tenth value for the financial year end key "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### XML\n",
    "\n",
    "(EXtensible Markup Language (XML) is a hierarchical data structure (known as a document) that uses tags to identify (or 'markup') the different types of information it contains; XML is also a file format (.xml) used to store XML documents<sup>[4]</sup>. Let's examine an XML dataset in Python:\n",
    "\n",
    "\n",
    "\n",
    "[4]: https://www.w3schools.com/xml/xml_whatis.asp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lxml import objectify # import Python module for handling XML files\n",
    "\n",
    "xml = objectify.parse(open('./data/oxfam-csv-2020-03-16.xml'))\n",
    "\n",
    "root = xml.getroot()\n",
    "root"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Graphs\n",
    "\n",
    "[Example of graph data structure e.g., an edge list]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are feeling flustered about having to master new data structures, then don't: converting from one structure to another is perfectly fine and common. For example, in my research I often convert dictonaries to data frames and save these as CSV files (see chapter 3). For now it is important that you familiarise yourself with the above structures, as much of the data available via the web is stored in these structures and file formats. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing code\n",
    "\n",
    "Perhaps the most crucial aspect of being a computational social scientist, the ability to write code can bring enourmous rewards. _Description/definition of programming and how it is similar to writing syntax for SPSS, Stata etc_\n",
    "\n",
    "Programming can be conceived as a social research method:\n",
    "\n",
    "> as a multipurpose toolkit for understanding and intervening in the (digital) social world in lots of different ways (Brooker, 2019, p.#).<sup>[2]</sup>\n",
    "\n",
    "[2]: https://doi.org/10.1177/0038026119840988\n",
    "\n",
    "This idea of \"Programming-as-Social Science\" carries with it two important distinctions (Brooker, 2019):\n",
    "1. **Coding-as-method** - using code to interact with or probe the social world (e.g. through data collection scripts).\n",
    "2. **Programming-as-analysis** - employing a coding mindset/knowledge of code to conceptualise and research social phenomena differently (e.g. ).\n",
    "\n",
    "Though the objective of any research project is to produce a robust and defensible finding (theoretical or empirical), the manner in which you conduct your activities is increasingly important. This impinges on the code you write, also. There is a school of thought that emphasises the readability and fluency of code, known as _literate programming (LP)_. The father of this approach, Donald Knuth (n.d.), summarises its high level aim:\n",
    "\n",
    "> Let us change our traditional attitude to the construction of programs: Instead of imagining that our main task is to instruct a computer what to do, let us concentrate rather on explaining to human beings what we want a computer to do.<sup>[3]</sup>\n",
    "\n",
    "Such a statement probably appears grandoise and abstract, but there are important practical implications of this idea. The coder (or essayist in LP parlance):\n",
    "\n",
    "> chooses the names of variables carefully and explains what each variable means. He or she strives for a program that is comprehensible because its concepts have been introduced in an order that is best for human understanding.\n",
    "\n",
    "Being a literate programmer does not mean writing screeds of comments and headings for the sake of it, far from it (remember: conciseness is paramount). We'll cover this topic in more detail in section 1.3.5 (add anchor).\n",
    "\n",
    "[3]: http://www.literateprogramming.com/knuthweb.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Documenting and enhancing your workflow\n",
    "\n",
    "There is a growing movement across the scientific community for greater transparency and reproducibility of research. Put simply, \"Reproducible research is necessary to ensure that scientific work can be trusted.\"<sup>[5]</sup>\n",
    "\n",
    "Reproducibility can be summarised as the availability of data and code to fully rerun an analysis. The Turing Way provides a delineation of the various connotations of reproducibility and related terms:\n",
    "* **Reproducible**: A result is reproducible when the same analysis steps performed on the same dataset consistently produces the same answer.\n",
    "* **Replicable**: A result is replicable when the same analysis performed on different datasets produces qualitatively similar answers.\n",
    "* **Robust**: A result is robust when the same dataset is subjected to different analysis workflows to answer the same research question (for example one pipeline written in R and another written in Python) and a qualitatively similar or identical answer is produced. Robust results show that the work is not dependent on the specificities of the programming language chosen to perform the analysis.\n",
    "* **Generalisable**: Combining replicable and robust findings allow us to form generalisable results. Note that running an analysis on a different software implementation and with a different dataset does not provide generalised results. There will be many more steps to know how well the work applies to all the different aspects of the research question. Generalised is an important step towards understanding that the result is not dependent on a particular dataset nor a particular version of the analysis pipeline.\n",
    "\n",
    "\n",
    "Professor Vernon Gayle of the University of Edinburgh has distilled reproducibility best practices into the following guidance (or rules) for social science research:\n",
    "1. Tell us about your software.\n",
    "2. Tells us about your data.\n",
    "3. Show us how you got your data ready.\n",
    "4. Show us all the analysis you did.\n",
    "5. Save all of this work openly.\n",
    "\n",
    "\n",
    "*Further Resources:*\n",
    "* [The Turing Way](https://the-turing-way.netlify.com) - Chapter 2.\n",
    "* [New Rules of the Sociological Method](https://github.com/vernongayle/new_rules_of_the_sociological_method/blob/master/noobs.ipynb).\n",
    "\n",
    "What is the relation between CSS and reproducible research. Well, the former provides a suite of tools and best practices for achieving the latter. Let's run through some of these quickly:\n",
    "* **Jupyter Notebooks**: the materials you are working through were written in a Jupyter notebook, a software application that enables you to interleave live code, results and narrative in a single file. Traditionally, social scientists save their data cleaning and analysis work in one or more files (e.g., Stata DO files), and write up the results in another file (e.g., a MS Word or Latex file). Jupyter notebooks re-establish the connection between conducting and reporting research activities. As [Barba et al. (2019)](https://jupyter4edu.github.io/jupyter-edu-book/) espouse:\n",
    "> In a world where every subject matter can have a data-supported treatment, where computational devices are omnipresent and pervasive, the union of natural language and computation creates compelling communication and learning opportunities.\n",
    "\n",
    "* Github: \n",
    "\n",
    "[J. Scott Long's Workflow of Data Analysis Using Stata]\n",
    "\n",
    "[FAIR principles]\n",
    "\n",
    "[Citing data]\n",
    "    \n",
    "[5]: https://the-turing-way.netlify.com/introduction/introduction.html\n",
    "\n",
    "The most powerful aspect of the technologies outlined above is that they **integrate** with each other. For example, you can conduct and document your analysis in a Jupyter notebook, save it publicly in a Github repostitory, and then use mybinder.org to allow others to reproduce your analysis using only their web browser.\n",
    "\n",
    "<!-- More material added by JK. Just notes, really. -->\n",
    "<!-- Citing sources \n",
    "Collaborative work and version control \n",
    "Replication. Replication. Replication. \n",
    "Sharing data  -->\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%HTML\n",
    "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/a5i42lSj-L4\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Hopefully this chapter has demystified aspects of CSS and whetted your appetite for some applied work. The subsequent chapters provide plenty of opportunity to practice CSS with various forms of data. For now I wanted to reflect on some outstanding issues.\n",
    "\n",
    "<!-- #### Python vs R vs Julia vs ....\n",
    "\n",
    "[Perhaps a table with some properties of each?] The general point is it's your choice.\n",
    " -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bibliography\n",
    "\n",
    "Brooker, P. (2020). Programming in Python for Social Scientists. London: Sage Publications.\n",
    "\n",
    "Kimberg, D. Y., et al. (1997). \"Effects of bromocriptine on human subjects depend on working memory capacity.\" Neuroreport 8(16): 3581-3585.\n",
    "\n",
    "Simon, H. A. (1997). Models of bounded rationality: Empirically grounded economic reason, MIT press.\n",
    "\n",
    "Pinker, S. (2003). The language instinct: How the mind creates language, Penguin UK.\n",
    "\n",
    "Kahneman, D. (2011). Thinking, fast and slow, Macmillan."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- ## Further Reading and Resources\n",
    "\n",
    "[Copy AQMEN reading lists] -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
